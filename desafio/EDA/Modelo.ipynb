{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIBRERIAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manejo de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Baselines y optimización\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, AdaBoostClassifier, GradientBoostingClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score, precision_score, recall_score, \\\n",
    "roc_curve, roc_auc_score, ConfusionMatrixDisplay, multilabel_confusion_matrix\n",
    "\n",
    "\n",
    "# Warnigs\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CARGA DE DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(\"./data/X_NEW.csv\")\n",
    "\n",
    "df_y = pd.read_csv(\"./data/transformed_df1.csv\")\n",
    "y = df_y[\"income\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "income\n",
       "0.0    29265\n",
       "1.0     9975\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SEPARACIÓN DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN, TEST = train_test_split(X, test_size=0.2, random_state=42)\n",
    "\n",
    "y_train, y_test = train_test_split(y,test_size=0.2, random_state=42)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(TRAIN, y_train, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BASELINES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression_accuracy</th>\n",
       "      <td>0.799582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression_f1_macro</th>\n",
       "      <td>0.687531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC_accuracy</th>\n",
       "      <td>0.745244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC_f1_macro</th>\n",
       "      <td>0.427014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree_accuracy</th>\n",
       "      <td>0.799126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree_f1_macro</th>\n",
       "      <td>0.738486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest_accuracy</th>\n",
       "      <td>0.836671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest_f1_macro</th>\n",
       "      <td>0.774057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost_accuracy</th>\n",
       "      <td>0.850505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost_f1_macro</th>\n",
       "      <td>0.785294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoost_accuracy</th>\n",
       "      <td>0.855921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoost_f1_macro</th>\n",
       "      <td>0.793246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HistGradientBoosting_accuracy</th>\n",
       "      <td>0.854920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HistGradientBoosting_f1_macro</th>\n",
       "      <td>0.795529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      0\n",
       "LogisticRegression_accuracy    0.799582\n",
       "LogisticRegression_f1_macro    0.687531\n",
       "SVC_accuracy                   0.745244\n",
       "SVC_f1_macro                   0.427014\n",
       "DecisionTree_accuracy          0.799126\n",
       "DecisionTree_f1_macro          0.738486\n",
       "RandomForest_accuracy          0.836671\n",
       "RandomForest_f1_macro          0.774057\n",
       "AdaBoost_accuracy              0.850505\n",
       "AdaBoost_f1_macro              0.785294\n",
       "GradientBoost_accuracy         0.855921\n",
       "GradientBoost_f1_macro         0.793246\n",
       "HistGradientBoosting_accuracy  0.854920\n",
       "HistGradientBoosting_f1_macro  0.795529"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# modelos\n",
    "modelos = {\n",
    "    \"LogisticRegression\": LogisticRegression(),\n",
    "    \"SVC\": SVC(),\n",
    "    \"DecisionTree\": DecisionTreeClassifier(),\n",
    "    \"RandomForest\": RandomForestClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "    \"GradientBoost\": GradientBoostingClassifier(),\n",
    "    \"HistGradientBoosting\": HistGradientBoostingClassifier()\n",
    "}\n",
    "\n",
    "# Define las métricas a usar\n",
    "resultados_dict = {}\n",
    "metricas = [\"accuracy\", \"f1_macro\"]\n",
    "\n",
    "\n",
    "for nombre_modelo, modelo in modelos.items():\n",
    "    cv_resultados = cross_validate(modelo, X_train, y_train, cv=5, scoring=metricas)\n",
    "    \n",
    "    for metrica in metricas:\n",
    "        clave = f\"{nombre_modelo}_{metrica}\"\n",
    "        resultados_dict[clave] = cv_resultados[f\"test_{metrica}\"].mean()\n",
    "\n",
    "        for metrica in metricas:\n",
    "            clave = f\"{nombre_modelo}_{metrica}\"\n",
    "            resultados_dict[clave] = cv_resultados[f\"test_{metrica}\"].mean()\n",
    "\n",
    "resultados_df = pd.DataFrame([resultados_dict])\n",
    "\n",
    "resultados_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dt = 0.8042047143767255\n",
      "hgb = 0.8593119558292631\n",
      "rf = 0.8385007432575918\n"
     ]
    }
   ],
   "source": [
    "# Instanciando el voting\n",
    "VotingC = VotingClassifier(estimators=\n",
    "                          [\n",
    "                              (\"dt\", DecisionTreeClassifier(random_state=42)),\n",
    "                              (\"hgb\", HistGradientBoostingClassifier(random_state=42)),\n",
    "                              (\"rf\", RandomForestClassifier(random_state=42))\n",
    "                          ])\n",
    "# Entrenando el voting\n",
    "VotingC.fit(X_train, y_train)\n",
    "\n",
    "#monstrando resultados\n",
    "for name, clf in VotingC.named_estimators_.items():\n",
    "    print(name, \"=\", clf.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elegimos hgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'l2_regularization': 0.1, 'learning_rate': 0.1, 'max_bins': 255, 'max_depth': 3, 'max_iter': 500, 'min_samples_leaf': 10}\n"
     ]
    }
   ],
   "source": [
    "# parámetros a evaluar\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_iter': [100, 500, 1000],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_samples_leaf': [10, 20, 50],\n",
    "    'l2_regularization': [0.0, 0.1, 0.5],\n",
    "    'max_bins': [255, 512]\n",
    "}\n",
    "\n",
    "# modelo\n",
    "hgb = HistGradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# gridsearch\n",
    "grid_search = GridSearchCV(hgb,\n",
    "                           param_grid,\n",
    "                           cv=5,\n",
    "                           scoring='neg_root_mean_squared_error',\n",
    "                           n_jobs=-1\n",
    "                          )\n",
    "\n",
    "# Entrenamiento\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# instanciando modelo entrenado en una variable\n",
    "hgb = grid_search.best_estimator_\n",
    "\n",
    "# mostrando mejores valores\n",
    "\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MÉTRICAS Y VALIDACIÓN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.8650678074087558\n",
      "train f1: 0.703648175912044\n"
     ]
    }
   ],
   "source": [
    "pred = hgb.predict(X_train)\n",
    "\n",
    "print(\"train accuracy:\", accuracy_score(y_train, pred))\n",
    "print('train f1:', f1_score(y_train, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val accuracy: 0.8603737523890422\n",
      "val f1: 0.6905154153918569\n"
     ]
    }
   ],
   "source": [
    "pred = hgb.predict(X_val)\n",
    "\n",
    "print(\"val accuracy:\", accuracy_score(y_val, pred))\n",
    "print('val f1:', f1_score(y_val, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8688837920489296\n",
      "f1: 0.7110362257792755\n"
     ]
    }
   ],
   "source": [
    "pred_test = hgb.predict(TEST)\n",
    "print(\"accuracy:\", accuracy_score(y_test, pred_test))\n",
    "print(\"f1:\", f1_score(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La bondad del modelo es realmente buena, no hay overfitting ni underfitting, se ajusta perfectamente a una predicción real."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
